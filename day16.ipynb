{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('엄마', 0.8541994690895081),\n",
       " ('아저씨', 0.6801633834838867),\n",
       " ('신혼', 0.6701761484146118),\n",
       " ('친구', 0.6636468172073364),\n",
       " ('할머니', 0.6597239375114441),\n",
       " ('어디가', 0.6566115617752075),\n",
       " ('아줌마', 0.6550686359405518),\n",
       " ('선생님', 0.6481844782829285),\n",
       " ('옆집', 0.6473677754402161),\n",
       " ('짱아', 0.6224738955497742)]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from gensim.models import word2vec\n",
    "model = word2vec.Word2Vec.load('data_text/wiki.model')\n",
    "model.wv.most_similar(positive=['아빠','여성'], negative=['남성'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('도쿄', 0.6553004384040833),\n",
       " ('오사카', 0.6442416906356812),\n",
       " ('교토', 0.6120120286941528),\n",
       " ('경성부', 0.5605552196502686),\n",
       " ('서울특별시', 0.5367318391799927),\n",
       " ('종로', 0.5275624990463257),\n",
       " ('동대문', 0.5270220041275024),\n",
       " ('경성', 0.518776535987854),\n",
       " ('간토', 0.5171927213668823),\n",
       " ('도쿄도', 0.5089890956878662)]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.wv.most_similar(positive=['서울','일본'], negative=['한국'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('북경', 0.688490629196167),\n",
       " ('베이징', 0.6430553197860718),\n",
       " ('운남성', 0.6356074810028076),\n",
       " ('절강성', 0.6335686445236206),\n",
       " ('봉천', 0.6251154541969299),\n",
       " ('北京', 0.6066190600395203),\n",
       " ('충칭', 0.6049784421920776),\n",
       " ('상하이', 0.6012908220291138),\n",
       " ('산동성', 0.6002797484397888),\n",
       " ('남경', 0.5982213020324707)]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.wv.most_similar(positive=['서울','중국'], negative=['한국'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('여자', 0.7491105198860168),\n",
       " ('어른', 0.5937405228614807),\n",
       " ('여자아이', 0.5855332612991333),\n",
       " ('남녀', 0.5672550201416016),\n",
       " ('남자에게', 0.5349474549293518),\n",
       " ('아가씨', 0.5177903771400452),\n",
       " ('여자도', 0.5176277160644531),\n",
       " ('그남자', 0.5144674181938171),\n",
       " ('女子', 0.5132307410240173),\n",
       " ('외로워', 0.511895477771759)]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.wv.most_similar(positive=['오른쪽','남자'], negative=['왼쪽'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('강남', 0.7033297419548035),\n",
       " ('동대문', 0.6378874778747559),\n",
       " ('평창동', 0.6323271989822388),\n",
       " ('이태원', 0.6287323236465454),\n",
       " ('여의도', 0.6166844367980957),\n",
       " ('연희동', 0.6138433218002319),\n",
       " ('강북', 0.6127862334251404),\n",
       " ('송파', 0.6107890009880066),\n",
       " ('광화문', 0.6103876233100891),\n",
       " ('인사동', 0.6073919534683228)]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.wv.most_similar(positive=['서울','맛집'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 5.4394007 , -0.01980883,  1.8977295 , -1.2494247 , -0.57004064,\n",
       "        2.567712  , -1.6200314 ,  1.2227641 ,  0.06029971, -1.7774072 ,\n",
       "       -0.83413273, -0.42919734, -1.2309037 , -1.1024537 , -0.8061239 ,\n",
       "        0.60492235,  1.8388214 , -1.2539688 , -1.9162188 , -1.8057042 ,\n",
       "       -0.394243  , -0.02844156, -0.9789619 , -0.11277597, -2.4982111 ,\n",
       "        0.04807808,  0.77322745, -1.721143  ,  1.2295259 ,  1.2636814 ,\n",
       "        3.6482937 ,  0.02867755, -3.1084127 ,  0.18008067,  0.42465106,\n",
       "        0.88798946,  2.722328  , -0.13288637,  0.12018509, -3.4317496 ,\n",
       "       -1.8254056 ,  2.2829404 ,  1.220089  ,  1.7054838 ,  0.6809032 ,\n",
       "       -1.1232904 ,  2.914248  , -1.3247129 ,  1.7813191 ,  1.9318762 ,\n",
       "        0.7911475 , -2.7863338 , -0.8349737 , -1.3192891 , -2.8759706 ,\n",
       "        1.0561261 ,  2.2265365 ,  0.47400182, -0.14831318, -1.8736936 ,\n",
       "       -1.2840827 , -0.44321913, -2.437037  , -0.8726344 , -1.0094637 ,\n",
       "        1.2541952 , -0.12605311, -1.9677713 , -0.8863553 ,  1.458264  ,\n",
       "        0.94711727,  0.6597272 , -1.7322942 , -3.8332345 , -0.79239213,\n",
       "        2.5297177 , -1.6270517 ,  0.26226282,  0.32343593,  1.6574526 ,\n",
       "        2.2590566 ,  0.6953227 , -0.23145741,  0.4637879 , -1.1195817 ,\n",
       "        0.57157695,  1.4598438 , -0.66155267,  1.4022005 , -0.08984974,\n",
       "       -0.60685325, -0.4528679 , -0.42978635,  1.5736911 , -0.02752416,\n",
       "        0.06800702,  0.7243481 ,  1.8024194 ,  2.113656  ,  3.2839386 ],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.wv['고양이']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 베이지안 필터 사용하기\n",
    "import math, sys\n",
    "from konlpy.tag import Twitter\n",
    "\n",
    "class BayesianFilter:\n",
    "    \"\"\"베이지안 필터\"\"\"\n",
    "    def __init__(self):\n",
    "        self.words = set()      # 출현 단어 기록\n",
    "        self.word_dict = {}     # 카테고리마다의 출현 횟수를 기록\n",
    "        self.category_dict = {} # 카테고리 출현 횟수 기록\n",
    "        \n",
    "    def split(self, text):\n",
    "        results = []\n",
    "        twitter = Twitter()\n",
    "        # 단어의 기본형 사용\n",
    "        malist = twitter.pos(text,norm=True,stem=True)\n",
    "        for word in malist:\n",
    "            # 어미/조사/구두점 등은 대상에서 제외\n",
    "            if not word[1] in ['Josa','Eomi','Punctuation']:\n",
    "                results.append(word[0])\n",
    "        return results\n",
    "    \n",
    "    # 단어와 카테고리의 출현 횟수 세기\n",
    "    def inc_word(self, word, category):\n",
    "        # 단어를 카테고리에 추가하기\n",
    "        if not category in self.word_dict:\n",
    "            self.word_dict[category] = {}\n",
    "        if not word in self.word_dict[category]:\n",
    "            self.word_dict[category][word] = 0\n",
    "        self.word_dict[category][word] += 1\n",
    "        self.words.add(word)\n",
    "        \n",
    "    def inc_category(self, category):\n",
    "        # 카테고리 계산하기\n",
    "        if not category in self.category_dict:\n",
    "            self.category_dict[category] = 0\n",
    "        self.category_dict[category] += 1\n",
    "        \n",
    "    # 텍스트 학습하기\n",
    "    def fit(self, text, category):\n",
    "        \"\"\"텍스트 학습\"\"\"\n",
    "        word_list = self.split(text)\n",
    "        for word in word_list:\n",
    "            self.inc_word(word, category)\n",
    "        self.inc_category(category)\n",
    "    \n",
    "    # 단어 리스트에 점수 매기기\n",
    "    def score(self, words, category):\n",
    "        score = math.log(self.category_prob(category))\n",
    "        for word in words:\n",
    "            score += math.log(self.word_prob(word, category))\n",
    "        return score\n",
    "    \n",
    "    # 에측하기\n",
    "    def predict(self, text):\n",
    "        best_category = None\n",
    "        max_score = -sys.maxsize\n",
    "        words = self.split(text)\n",
    "        score_list = []\n",
    "        for category in self.category_dict.keys():\n",
    "            score = self.score(words, category)\n",
    "            score_list.append((category,score))\n",
    "            if score > max_score:\n",
    "                max_score = score\n",
    "                best_category = category\n",
    "        return best_category, score_list\n",
    "    \n",
    "    # 카테고리 내부의 단어 출현 횟수 구하기\n",
    "    def get_word_count(self, word, category):\n",
    "        if word in self.word_dict[category]:\n",
    "            return self.word_dict[category][word]\n",
    "        else:\n",
    "            return 0\n",
    "    \n",
    "    # 카테고리 계산\n",
    "    def category_prob(self, category):\n",
    "        sum_categories = sum(self.category_dict.values())\n",
    "        category_v = self.category_dict[category]\n",
    "        return category_v / sum_categories\n",
    "    \n",
    "    # 카테고리 내부의 단어 출현 비율 계산\n",
    "    def word_prob(self, word, category):\n",
    "        n = self.get_word_count(word, category) + 1\n",
    "        d = sum(self.word_dict[category].values()) + len(self.words)\n",
    "        return n / d\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "결과 =  광고\n",
      "[('광고', -19.16807495974667), ('중요', -20.449365773467083)]\n"
     ]
    }
   ],
   "source": [
    "# from bayes import BayesianFilter   => 모듈을 호출하여 BaysianFilter를 로드\n",
    "bf = BayesianFilter()\n",
    "# 텍스트 학습\n",
    "bf.fit(\"파격 세일 - 오늘까지만 30%할인\", \"광고\")\n",
    "bf.fit(\"쿠폰 선물 & 무료 배송\", \"광고\")\n",
    "bf.fit(\"현대 백화점 세일\", \"광고\")\n",
    "bf.fit(\"봄과 함께 찾아온 따뜻한 신제품 소식\",\"광고\")\n",
    "bf.fit(\"인기 제품 기간 한정 세일\", \"광고\")\n",
    "bf.fit(\"오늘 일정 확인\", \"중요\")\n",
    "bf.fit(\"프로젝트 진행 상황 보고\", \"중요\")\n",
    "bf.fit(\"계약 잘 부탁드립니다.\", \"중요\")\n",
    "bf.fit(\"회의 일정이 등록되었습니다.\", \"중요\")\n",
    "bf.fit(\"오늘 일정이 없습니다.\", \"중요\")\n",
    "\n",
    "# 예측\n",
    "pre, scorelist = bf.predict(\"재고 정리 할인, 무료 배송\")\n",
    "print(\"결과 = \", pre)\n",
    "print(scorelist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, glob, json\n",
    "\n",
    "root_dir = './newstext'\n",
    "dic_file = root_dir + \"/word-dic.json\"\n",
    "data_file = root_dir + '/data.json'\n",
    "data_file_min = root_dir + '/data-mini.json'\n",
    "\n",
    "# 어구를 자르고 ID로 변환하기\n",
    "word_dic = {\"_MAX\" : 0}\n",
    "def text_to_ids(text):\n",
    "    text = text.strip()\n",
    "    words = text.split(\" \")\n",
    "    result = []\n",
    "    for n in words:\n",
    "        n = n.strip()\n",
    "        if n == \"\": continue\n",
    "        if not n in word_dic:\n",
    "            wid = word_dic[n] = word_dic[\"_MAX\"]\n",
    "            word_dic[\"_MAX\"] += 1\n",
    "            print(wid, n)\n",
    "        else:\n",
    "            wid = word_dic[n]\n",
    "        result.append(wid)\n",
    "    return result\n",
    "# 파일을 읽고 고정 길이의 배열 리턴하기 (※2)\n",
    "def file_to_ids(fname):\n",
    "    with open(fname, \"r\",encoding='utf-8') as f:\n",
    "        text = f.read()\n",
    "        return text_to_ids(text)\n",
    "# 딕셔너리에 단어 모두 등록하기 (3)\n",
    "def register_dic():\n",
    "    files = glob.glob(root_dir+\"/*/*.wakati\", recursive=True)\n",
    "    for i in files:\n",
    "        file_to_ids(i)\n",
    "# 파일 내부의 단어 세기 (X4)\n",
    "def count_file_freq(fname):\n",
    "    cnt = [0 for n in range(word_dic[\"_MAX\"])]\n",
    "    with open(fname, \"r\",encoding='utf-8') as f:\n",
    "        text = f.read().strip()\n",
    "        ids = text_to_ids(text)\n",
    "        for wid in ids:\n",
    "            cnt[wid] += 1\n",
    "    return cnt\n",
    "# 카테고리마다 파일 읽어 들이기 (5)\n",
    "def count_freq(limit = 0):\n",
    "    X = []\n",
    "    Y = []\n",
    "    max_words = word_dic[\"_MAX\"]\n",
    "    cat_names = []\n",
    "    for cat in os.listdir(root_dir):\n",
    "        cat_dir = root_dir + \"/\" + cat\n",
    "        if not os.path.isdir(cat_dir): continue\n",
    "        cat_idx = len(cat_names)\n",
    "        cat_names.append(cat)\n",
    "        files = glob.glob(cat_dir+\"/*.wakati\")\n",
    "        i = 0\n",
    "        for path in files:\n",
    "            print(path)\n",
    "            cnt = count_file_freq(path)\n",
    "            X.append(cnt)\n",
    "            Y.append(cat_idx)\n",
    "            if limit > 0:\n",
    "                if i > limit: break\n",
    "                i += 1\n",
    "    return X,Y\n",
    "# 단어 딕셔너리 만들기 (※5)\n",
    "if os.path.exists(dic_file):\n",
    "    word_dic = json.load(open(dic_file))\n",
    "else:\n",
    "    register_dic()\n",
    "    json.dump(word_dic, open(dic_file, \"w\",encoding='utf-8'))\n",
    "# 벡터를 파일로 출력하기 (※6)\n",
    "# 테스트 목적의 소규모 데이터 만들기\n",
    "X, Y = count_freq(20)\n",
    "json.dump({\"X\": X, \"Y\": Y}, open(data_file_min,\"w\",encoding='utf-8'))\n",
    "# 전체 데이터를 기반으로 데이터 만들기\n",
    "X, Y = count_freq()\n",
    "json.dump({\"X\": X, \"Y\": Y}, open(data_file, \"w\",encoding='utf-8'))\n",
    "print(\"ok\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MLP로 텍스트 분류하기\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "from keras.utils import np_utils\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import model_selection, metrics\n",
    "import json\n",
    "import numpy as np\n",
    "\n",
    "max_words = 56681   # 입력단어수: word-dic.json참고\n",
    "nb_classes = 6      # 9개의 카테고리\n",
    "\n",
    "batch_size = 64\n",
    "nb_epoch = 5\n",
    "\n",
    "# MLP 모델 생성하기\n",
    "def build_model():\n",
    "    model = Sequential()\n",
    "    model.add(Dense(512, input_shape=(max_words,)))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(nb_classes))\n",
    "    model.add(Activation('softmax'))\n",
    "    model.compile(loss='categorical_crossentropy',\n",
    "                  optimizer='adam',\n",
    "                  metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "# 데이터 읽어 들이기\n",
    "# data = json.load(open('./data_text/data-mini.json'))\n",
    "data = json.load(open('./newstext/data.json'))\n",
    "X = data['X']   # 텍스트를 나타내는 데이터\n",
    "Y = data['Y']   # 카테고리 데이터\n",
    "\n",
    "\n",
    "# 학습하기\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X,Y)\n",
    "Y_train = np_utils.to_categorical(Y_train, nb_classes)\n",
    "print(len(X_train),len(Y_train))\n",
    "\n",
    "model = KerasClassifier(\n",
    "    build_fn=build_model,\n",
    "    epochs=nb_epoch,\n",
    "    batch_size=batch_size\n",
    ")\n",
    "model.fit(X_train, Y_train)\n",
    "\n",
    "# 예측하기\n",
    "y = model.predict(X_test)\n",
    "ac_score = metrics.accuracy_score(Y_test, y)\n",
    "cl_report = metrics.classification_report(Y_test, y)\n",
    "print('정답률 = ',ac_score)\n",
    "print('리포트 =\\n',cl_report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "0 신촌역\n",
      "1 신천역\n",
      "2 신천군\n",
      "2 신발\n",
      "2 마곡역\n"
     ]
    }
   ],
   "source": [
    "def calc_distance(a,b):\n",
    "    \"\"\"레벤슈타인 거리 계산하기\"\"\"\n",
    "    if a == b: return 0\n",
    "    a_len = len(a)\n",
    "    b_len = len(b)\n",
    "    if a == \"\": return b_len\n",
    "    if b == \"\": return a_len\n",
    "    # 2차원 표 (a_len+1, b_len+1) 준비하기\n",
    "    matrix = [[] for i in range(a_len+1)]\n",
    "    for i in range(a_len+1):    # 0으로 초기화\n",
    "        matrix[i] = [0 for j in range(b_len+1)]\n",
    "    # 0일 때 초깃값을 설정\n",
    "    for i in range(a_len+1):\n",
    "        matrix[i][0] = i\n",
    "    for j in range(b_len+1):\n",
    "        matrix[0][j] = j\n",
    "    # 표 채우기\n",
    "    for i in range(1, a_len+1):\n",
    "        ac = a[i-1]\n",
    "        for j in range(1, b_len+1):\n",
    "            bc = b[j-1]\n",
    "            cost = 0 if (ac==bc) else 1\n",
    "            matrix[i][j] = min([\n",
    "                matrix[i-1][j] + 1, # 문자삽입\n",
    "                matrix[i][j-1] + 1, # 문자제거\n",
    "                matrix[i-1][j-1] + cost # 문자변경\n",
    "            ])\n",
    "    return matrix[a_len][b_len]\n",
    "\n",
    "# \"가나다라\"와 \"가마바라\" 의 거리\n",
    "print(calc_distance(\"가나다라\",\"가마바라\"))\n",
    "\n",
    "# 실행 예\n",
    "samples = [\"신촌역\", \"신천군\", \"신천역\", \"신발\", \"마곡역\"]\n",
    "base = samples[0]\n",
    "r = sorted(samples, key=lambda n: calc_distance(base,n))\n",
    "for n in r:\n",
    "    print(calc_distance(base,n),n)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "26de051ba29f2982a8de78e945f0abaf191376122a1563185a90213a26c5da77"
  },
  "kernelspec": {
   "display_name": "Python 3.10.3 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
